# 4.ClickHouse从入门到放弃

## 4.1 简介

#### 4.1.1 定义

ClickHouse是一个用于联机分析(OLAP)的列式数据库管理系统(DBMS)。

ClickHouse最初是为 [YandexMetrica](https://metrica.yandex.com/) [世界第二大Web分析平台](http://w3techs.com/technologies/overview/traffic_analysis/all) 而开发的。多年来一直作为该系统的核心组件被该系统持续使用着。目前为止，该系统在ClickHouse中有超过13万亿条记录，并且每天超过200多亿个事件被处理。它允许直接从原始数据中动态查询并生成报告。

#### 4.1.2 OLAP场景的关键特征

- 绝大多数是读请求
- 数据以相当大的批次(> 1000行)更新，而不是单行更新;或者根本没有更新。
- 已添加到数据库的数据不能修改。
- 对于读取，从数据库中提取相当多的行，但只提取列的一小部分。
- 宽表，即每个表包含着大量的列
- 查询相对较少(通常每台服务器每秒查询数百次或更少)
- 对于简单查询，允许延迟大约50毫秒
- 列中的数据相对较小：数字和短字符串(例如，每个URL 60个字节)
- 处理单个查询时需要高吞吐量(每台服务器每秒可达数十亿行)
- 事务不是必须的
- 对数据一致性要求低
- 每个查询有一个大表。除了他以外，其他的都很小。
- 查询结果明显小于源数据。换句话说，数据经过过滤或聚合，因此结果适合于单个服务器的RAM中

#### 4.1.3 测试数据

根据官网的介绍(  https://clickhouse.tech/benchmark/dbms/)，ClickHouse在相同的[服务器](https://www.yisu.com/)配置与数据量下，平均响应速度：  

- Vertica的2.63倍(Vertica是一款收费的列式存储数据库)
- InfiniDB的17倍(可伸缩的分析数据库引擎，基于[Mysql](https://www.yisu.com/mysql/)搭建)
- MonetDB的27倍(开源的列式数据库)
- Hive的126倍
- MySQL的429倍
- Greenplum的10倍
- Spark的1倍

#### 4.1.4 性能

根据Yandex的内部测试结果，ClickHouse表现出了比同类可比较产品更优的性能。你可以在 [这里](https://clickhouse.com/benchmark/dbms/) 查看具体的测试结果。

许多其他的测试也证实这一点。你可以使用互联网搜索到它们，或者你也可以从 [我们收集的部分相关连接](https://clickhouse.com/#independent-benchmarks) 中查看。

##### 单个大查询的吞吐量

吞吐量可以使用每秒处理的行数或每秒处理的字节数来衡量。如果数据被放置在page cache中，则一个不太复杂的查询在单个服务器上大约能够以2-10GB／s（未压缩）的速度进行处理（对于简单的查询，速度可以达到30GB／s）。如果数据没有在page cache中的话，那么速度将取决于你的磁盘系统和数据的压缩率。例如，如果一个磁盘允许以400MB／s的速度读取数据，并且数据压缩率是3，则数据的处理速度为1.2GB/s。这意味着，如果你是在提取一个10字节的列，那么它的处理速度大约是1-2亿行每秒。

对于分布式处理，处理速度几乎是线性扩展的，但这受限于聚合或排序的结果不是那么大的情况下。

##### 处理短查询的延迟时间

如果一个查询使用主键并且没有太多行(几十万)进行处理，并且没有查询太多的列，那么在数据被page cache缓存的情况下，它的延迟应该小于50毫秒(在最佳的情况下应该小于10毫秒)。 否则，延迟取决于数据的查找次数。如果你当前使用的是HDD，在数据没有加载的情况下，查询所需要的延迟可以通过以下公式计算得知： 查找时间（10 ms） * 查询的列的数量 * 查询的数据块的数量。

##### 处理大量短查询的吞吐量

在相同的情况下，ClickHouse可以在单个服务器上每秒处理数百个查询（在最佳的情况下最多可以处理数千个）。但是由于这不适用于分析型场景。因此我们建议每秒最多查询100次。

##### 数据的写入性能

我们建议每次写入不少于1000行的批量写入，或每秒不超过一个写入请求。当使用tab-separated格式将一份数据写入到MergeTree表中时，写入速度大约为50到200MB/s。如果您写入的数据每行为1Kb，那么写入的速度为50，000到200，000行每秒。如果您的行更小，那么写入速度将更高。为了提高写入性能，您可以使用多个INSERT进行并行写入，这将带来线性的性能提升。



#### 4.1.5 ClickHouse 优缺点，存在的问题和规划（基于版本20.8）

参考文档：https://www.infoq.cn/article/VggxS8hQbEwG1z3NdtT0

##### 1、优点

###### **1）数据压缩比高，存储成本低。**

ClickHouse 最大的特点就是快，其他的比如数据压缩比高、存储成本低等等，所以以前我们有很多的功能埋点都集中在 ES 里面，但是从年初开始到现在应该是把所有的 ES 埋点全部转成 ClickHouse，所以根据 ClickHouse 的数据压缩比，首先就可以评估到我们硬件成本比采用 ES 的方案时它至少降低 60%以上，日志在 ES 和 ClickHouse 上面的查询性能这里就不展开对比。

###### 2）支持常用的 SQL 语法，写入速度非常快，适用于大量的数据更新

它的语法跟 MySQL 比较类似，但是它有一个特点就是它的 join 不能太复杂，A 表 join B 表的时候不能直接 join C 表，需要把 A 表 join B 表的 AS 成一个带别名的临时表以后再去 join C 表，所以它的语法主要还是在 join 上面会比较独特。如果你的查询语句很复杂，你的 join 就会看起来很长，所以查询语句可读性不像 SQL 那么好理解。但是它的写入速度非常快，特别适合于像我们的离线数据每天都是几亿几十亿数据量的更新。官方资料介绍它是按照每秒钟 50-200 兆导入速度。

###### 3）依赖稀疏索引，列式存储，CPU/内存的充分利用造就了优秀的计算能力，并且不用考虑左侧原则

它是依赖稀疏索引，列式存储。我们在去取数据的时候，经常会只取某几个字段，按列存储对 IO 比较友好，减少 IO 的次数，也是在查询速度上一个辅助。再就是它很大程度利用了 CPU，我们都知道 MySQL 是单线程获取数据的，但是 ClickHouse 服务器上面有多少个 CPU，它就会用服务器的一半 CPU 去拉，像我们平时用的 40 核或者 32 核的物理机，基本上拿一半的核去拉数据。当然，这个可以修改配置文件每个 query 用多少 CPU。因为它一个查询需要消耗太多的 CPU，所以在高并发上面是一个短板。当然，我们也不需要考虑什么左侧原则之类的，就算你的查询条件不在索引里面，ClickHouse 的查询一样非常快。

##### 2、缺点

###### 1）不支持事务，没有真正的 update/delete

不支持事务，没有真正的 update/delete，主要还是高并发的短板，所以我们应用都在一些能 Hold 住的场景下。如果对外放在公网，这个 QPS 就可能很难控制，这种场景用 ClickHouse 就要谨慎。

###### 2）不支持高并发，可以根据实际情况修改 qps 相关配置文件

ClickHouse 吃 CPU，可能团队十个人通过执行同一个查询就可以把一台 CPU 40C 的物理机打爆，但是为什么我前面说我们有 700 亿的数据只需要十台物理机就可以扛得住呢？其实我们对 ClickHouse 做了很多保护。

##### 3、需要解决的问题（基于20.8版本）：

###### 1）部分场景下内存泄漏

现在我们遇到的一些问题是当你服务器上面的数据存储超过你的服务器内存时，会存在内存泄漏。但每天就掉一点点，比如说 128g 内存可能 2-3 个月时间可用内存只有 60%左右，但是这个还是在我用 2018 年的版本时候。我们现在也正在灰度升级到今年的 20.9 的版本，看似还是没有解决。

###### 2）历史数据更新的 CPU 消耗问题。

###### 3）死锁问题

我们每天大量的数据更新后为了减少用户端使用的影响，我们都是通过 rename 的方式，但对于有些查询并发比较高的表 rename 的时候会存在死锁的情况，这个在 20.9 的版本中已修复。

##### 4、建议性问题：

###### 1）如何保证高优先级的表在服务器维护后第一时间投入生产应用的问题?

对于 ClickHouse 一个建议性的问题就是服务器重启以后，如果服务器上面的数据量过大，可能要很久的数据加载，重新整理文件后服务器才可用，所以这个我跟俄罗斯研发团队有过沟通，让表分级，高优先级的表先启动，可以早点让服务器起来后投入生产应用，后面的表可以通过 lazy 的方式加载。

###### 2）新功能的实践：

1）20.9 的新版支持订阅 MySQL 的 binlog 方式同步数据
新功能的时间包括现在有订阅 MySQL 的 binlog 方式同步数据方式，这个我们发现最近几个版本都有在修复一些 bug，所以暂时没有应用，但如果这个做好了是可以用于更多的场景，也可以更好的接入实时数据。
2）查看执行计划
以前的版本只能到服务器上看执行日志，但这个比较费劲，现在可以像 SQL 一样直接看执行计划了。

#### 4.1.6 ClickHouse 应用小结

参考文档：https://www.infoq.cn/article/VggxS8hQbEwG1z3NdtT0

##### 1）数据导入之前要评估好分区字段

ClickHouse 因为是根据分区文件存储的，如果说你的分区字段真实数据粒度很细，数据导入的时候就会把你的物理机打爆。其实数据量可能没有多少，但是因为你用的字段不合理，会产生大量的碎片文件，磁盘空间就会打到底。

##### 2）数据导入提前根据分区做好排序，避免同时写入过多分区导致 clickhouse 内部来不及 Merge

数据导入之前我们做好排序，这样可以降低数据导入后 ClickHouse 后台异步 Merge 的时候涉及到的分区数，肯定是涉及到的分区数越少服务器压力也会越小。

##### 3）左右表 join 的时候要注意数据量的变化

再就是左右表 join 的问题，ClickHouse 它必须要大表在左边，小表在右边。但是我们可能某些业务场景跑着跑着数据量会返过来了，这个时候我们需要有监控能及时发现并修改这个 join 关系。

##### 4）根据数据量以及应用场景评估是否采用分布式

分布式要根据应用场景来，如果你的应用场景向上汇总后数据量已经超过了单物理机的存储或者 CPU/内存瓶颈而不得不采用分布式 ClickHouse 也有很完善的 MPP 架构，但同时你也要维护好你的主 keyboard。

##### 5）监控好服务器的 CPU/内存波动

再就是做好监控，我前面说过 ClickHouse 的 CPU 拉到 60%的时候，基本上你的慢查询马上就出来了，所以我这边是有对 CPU 和内存的波动进行监控的，类似于 dump，这个我们抓下来以后就可以做分析。

##### 6）数据存储磁盘尽量采用 SSD

数据存储尽量用 SSD，因为我之前也开始用过机械硬盘，机械硬盘有一个问题就是当你的服务器要运维以后需要重启，这个时候数据要加载，我们现在单机数据量存储有超过了 200 亿以上，这还是我几个月前统计的。这个数据量如果说用机械硬盘的话，重启一次可能要等上好几个小时服务器才可用，所以尽量用 SSD，重启速度会快很多。

当然重启也有一个问题就是说会导致你的数据合并出现错乱，这是一个坑。所以我每次维护机器的时候，同一个集群我不会同时维护几台机器，我只会一台一台维护，A 机器好了以后会跟它的备用机器对比数据，否则机器起来了，但是数据不一定是对的，并且可能是一大片数据都是不对的。

##### 7）减少数据中文本信息的冗余存储

要减少一些中文信息的冗余存储，因为中文信息会导致整个服务器的 IO 很高，特别是导数据的时候。

##### 8）特别适用于数据量大，查询频次可控的场景，如数据分析、埋点日志系统

对于它的应用，我认为从成本角度来说，就像以前我们有很多业务数据的修改日志，大家开发的时候可能都习惯性的存到 MySQL 里面，但是实际上我认为这种数据非常适合于落到 ClickHouse 里面，比落到 MySQL 里面成本会更低，查询速度会更快。



## 4.2 环境搭建

### 4.2.1 版本选择

```text
ClickHouse: 22.4.5.9
CentOS: Linux release 7.9.2009
MySQL:MySQL-5.7
```



### 4.2.2 下载安装

采用官方预编译的`tgz`软件包方式安装。

参考文档：

https://clickhouse.com/docs/zh/getting-started/install

所需的版本可以通过`curl`或`wget`从存储库`https://packages.clickhouse.com/tgz/`下载。

```shell
# 查看最新版本 22.4.5.9

[root@localhost anchu]# curl -s https://packages.clickhouse.com/tgz/stable/ |grep -Eo '[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+' | sort -V -r | head -n 1
22.4.5.9

# 设置临时环境变量并下载

[anchu@localhost ~]$ LATEST_VERSION=$(curl -s https://packages.clickhouse.com/tgz/stable/ | \
>     grep -Eo '[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+' | sort -V -r | head -n 1)

[anchu@localhost ~]$ export LATEST_VERSION
[anchu@localhost ~]$ echo $LATEST_VERSION
22.4.5.9
[anchu@localhost ~]$ cd software/
[anchu@localhost software]$ mkdir clickhouse
[anchu@localhost software]$ cd clickhouse/

# 根据最新版本下载
[anchu@localhost clickhouse]$ curl -O "https://packages.clickhouse.com/tgz/stable/clickhouse-common-static-$LATEST_VERSION-amd64.tgz"


[anchu@localhost clickhouse]$ 
curl -O "https://packages.clickhouse.com/tgz/stable/clickhouse-common-static-dbg-$LATEST_VERSION-amd64.tgz"

[anchu@localhost clickhouse]$
curl -O "https://packages.clickhouse.com/tgz/stable/clickhouse-server-$LATEST_VERSION-amd64.tgz"

[anchu@localhost clickhouse]$ 
curl -O "https://packages.clickhouse.com/tgz/stable/clickhouse-client-$LATEST_VERSION-amd64.tgz"

# 查看并解压

[anchu@localhost clickhouse]$ ll -h
total 1011M
-rw-rw-r--. 1 anchu anchu  35K May 11 11:03 clickhouse-client-22.4.5.9-amd64.tgz
-rw-rw-r--. 1 anchu anchu 226M May 11 10:54 clickhouse-common-static-22.4.5.9-amd64.tgz
-rw-rw-r--. 1 anchu anchu 785M May 11 11:01 clickhouse-common-static-dbg-22.4.5.9-amd64.tgz
-rw-rw-r--. 1 anchu anchu  55K May 11 11:03 clickhouse-server-22.4.5.9-amd64.tgz

#解压安装
[anchu@localhost clickhouse]$  tar -xzvf "clickhouse-common-static-$LATEST_VERSION-amd64.tgz"
[anchu@localhost clickhouse]$  tar -xzvf "clickhouse-common-static-dbg-$LATEST_VERSION-amd64.tgz"
[anchu@localhost clickhouse]$  tar -xzvf "clickhouse-server-$LATEST_VERSION-amd64.tgz"
[anchu@localhost clickhouse]$  tar -xzvf "clickhouse-client-$LATEST_VERSION-amd64.tgz"

```

官网操作(需要注意要加操作系统类型，最新版本加入了操作系统名称amd64，原来的url无法下载数据)：

```shell
LATEST_VERSION=$(curl -s https://packages.clickhouse.com/tgz/stable/ | \
    grep -Eo '[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+' | sort -V -r | head -n 1)
export LATEST_VERSION

tar -xzvf "clickhouse-common-static-$LATEST_VERSION.tgz"
sudo "clickhouse-common-static-$LATEST_VERSION/install/doinst.sh"

tar -xzvf "clickhouse-common-static-dbg-$LATEST_VERSION.tgz"
sudo "clickhouse-common-static-dbg-$LATEST_VERSION/install/doinst.sh"

tar -xzvf "clickhouse-server-$LATEST_VERSION.tgz"
sudo "clickhouse-server-$LATEST_VERSION/install/doinst.sh"
sudo /etc/init.d/clickhouse-server start

tar -xzvf "clickhouse-client-$LATEST_VERSION.tgz"
sudo "clickhouse-client-$LATEST_VERSION/install/doinst.sh"
```

#注意 ：下面这个因为下载的时候没带amd64，导致下载的文件不对

![image-20220512150936245](文档图片/image-20220512150936245.png)

正常的下载如下：

![image-20220512153659381](文档图片/image-20220512153659381.png)

对于生产环境，建议使用最新的`stable`版本。你可以在GitHub页面https://github.com/ClickHouse/ClickHouse/tags找到它，它以后缀`-stable`标志。

![image-20220512152745029](文档图片/image-20220512152745029.png)

### 4.2.3 配置启动

首先，需要当前用户有sudo权限,配置如下

```shell
[root@localhost clickhouse]# su root
[root@localhost clickhouse]# chmod u+w /etc/sudoers
[root@localhost clickhouse]# vi /etc/sudoers
anchu   ALL=(ALL)       ALL
```

初始化

```shell
[anchu@localhost clickhouse]$ su anchu
Password: 
[anchu@localhost clickhouse]$ pwd
/home/anchu/software/clickhouse

[anchu@localhost clickhouse]$ sudo "clickhouse-common-static-$LATEST_VERSION/install/doinst.sh"

[anchu@localhost clickhouse]$sudo "clickhouse-common-static-dbg-$LATEST_VERSION/install/doinst.sh"

[anchu@localhost clickhouse] sudo "clickhouse-server-$LATEST_VERSION/install/doinst.sh"

# 安装clickhouse-server
[anchu@localhost clickhouse]$ sudo "clickhouse-server-$LATEST_VERSION/install/doinst.sh"

ClickHouse binary is already located at /usr/bin/clickhouse
Creating symlink /usr/bin/clickhouse-server to /usr/bin/clickhouse.
Creating symlink /usr/bin/clickhouse-client to /usr/bin/clickhouse.
Creating symlink /usr/bin/clickhouse-local to /usr/bin/clickhouse.
Creating symlink /usr/bin/clickhouse-benchmark to /usr/bin/clickhouse.
Creating symlink /usr/bin/clickhouse-copier to /usr/bin/clickhouse.
Creating symlink /usr/bin/clickhouse-obfuscator to /usr/bin/clickhouse.
Creating symlink /usr/bin/clickhouse-git-import to /usr/bin/clickhouse.
Creating symlink /usr/bin/clickhouse-compressor to /usr/bin/clickhouse.
Creating symlink /usr/bin/clickhouse-format to /usr/bin/clickhouse.
Symlink /usr/bin/clickhouse-extract-from-config already exists but it points to /home/anchu/software/clickhouse/clickhouse. Will replace the old symlink to /usr/bin/clickhouse.
Creating symlink /usr/bin/clickhouse-extract-from-config to /usr/bin/clickhouse.
Creating symlink /usr/bin/clickhouse-keeper to /usr/bin/clickhouse.
Creating symlink /usr/bin/clickhouse-keeper-converter to /usr/bin/clickhouse.
Creating clickhouse group if it does not exist.
 groupadd -r clickhouse
Creating clickhouse user if it does not exist.
 useradd -r --shell /bin/false --home-dir /nonexistent -g clickhouse clickhouse
Will set ulimits for clickhouse user in /etc/security/limits.d/clickhouse.conf.
Creating config directory /etc/clickhouse-server.
Creating config directory /etc/clickhouse-server/config.d that is used for tweaks of main server configuration.
Creating config directory /etc/clickhouse-server/users.d that is used for tweaks of users configuration.
Data path configuration override is saved to file /etc/clickhouse-server/config.d/data-paths.xml.
Log path configuration override is saved to file /etc/clickhouse-server/config.d/logger.xml.
User directory path configuration override is saved to file /etc/clickhouse-server/config.d/user-directories.xml.
OpenSSL path configuration override is saved to file /etc/clickhouse-server/config.d/openssl.xml.
Creating log directory /var/log/clickhouse-server.
Creating data directory /var/lib/clickhouse.
Creating pid directory /var/run/clickhouse-server.
 chown -R clickhouse:clickhouse '/var/log/clickhouse-server'
 chown -R clickhouse:clickhouse '/var/run/clickhouse-server'
 chown  clickhouse:clickhouse '/var/lib/clickhouse'
 groupadd -r clickhouse-bridge
 useradd -r --shell /bin/false --home-dir /nonexistent -g clickhouse-bridge clickhouse-bridge
 chown -R clickhouse-bridge:clickhouse-bridge '/usr/bin/clickhouse-odbc-bridge'
 chown -R clickhouse-bridge:clickhouse-bridge '/usr/bin/clickhouse-library-bridge'
Enter password for default user: 
Password for default user is saved in file /etc/clickhouse-server/users.d/default-password.xml.
Setting capabilities for clickhouse binary. This is optional.
Cannot set 'net_admin' or 'ipc_lock' or 'sys_nice' or 'net_bind_service' capability for clickhouse binary. This is optional. Taskstats accounting will be disabled. To enable taskstats accounting you may add the required capability later manually.
Allow server to accept connections from the network (default is localhost only), [y/N]: 
 chown -R clickhouse:clickhouse '/etc/clickhouse-server'

ClickHouse has been successfully installed.

Start clickhouse-server with:
 sudo clickhouse start
Start clickhouse-client with:
 clickhouse-client --password

#默认用户 default 密码 clickhouse


# 安装clickhouse-client
[anchu@localhost clickhouse]$  sudo "clickhouse-client-$LATEST_VERSION/install/doinst.sh"
```

![image-20220512160542489](文档图片/image-20220512160542489.png)

启动clickhouse-server

```shell
[anchu@localhost clickhouse]$  sudo clickhouse start
 chown -R clickhouse: '/var/run/clickhouse-server/'
Will run su -s /bin/sh 'clickhouse' -c '/usr/bin/clickhouse-server --config-file /etc/clickhouse-server/config.xml --pid-file /var/run/clickhouse-server/clickhouse-server.pid --daemon'
Waiting for server to start
Server started
```

启动clickhouse-client,并连接clickhouse-server  (--multiline等同于-m，支持sql换行)

```shell
[anchu@localhost clickhouse]$ clickhouse-client --user=default --password=clickhouse --host=127.0.0.1 --multiline
ClickHouse client version 22.4.5.9 (official build).
Connecting to 127.0.0.1:9000 as user default.
Connected to ClickHouse server version 22.4.5 revision 54455.

Warnings:
 * Linux transparent hugepage are set to "always".
 * Linux threads max count is too low.
 * Maximum number of threads is lower than 30000. There could be problems with handling a lot of simultaneous queries.

localhost :) show tables;

SHOW TABLES

Query id: f8a39afa-9152-4232-bb1e-aa67b2bddaca

Ok.

0 rows in set. Elapsed: 0.002 sec. 

localhost :) quit;
Bye.

```

查看进程

```shell
[anchu@localhost ~]$ ps -ef|grep clickhouse
clickho+  29606      1  0 11:30 ?        00:00:00 clickhouse-watchdog        --config-file /etc/clickhouse-server/config.xml --pid-file /var/run/clickhouse-server/clickhouse-server.pid --daemon
clickho+  29607  29606  1 11:30 ?        00:00:11 /usr/bin/clickhouse-server --config-file /etc/clickhouse-server/config.xml --pid-file /var/run/clickhouse-server/clickhouse-server.pid --daemon
anchu     29991  29295  0 11:40 pts/2    00:00:00 clickhouse-client --user=default --password=           -h 127.0.0.1 --port 9000 -m
anchu     30036  29855  0 11:45 pts/1    00:00:00 grep --color=auto clickhouse

```

登录数据库执行的每条SQL，ClickHouse都会自动记录到当前用户根路径的.clickhouse-client-history

```shell
[anchu@localhost ~]$ cat ~/.clickhouse-client-history
### 2022-05-11 11:34:31.179
show tables;
### 2022-05-11 11:37:23.508
quit;
### 2022-05-11 11:41:50.100
select 1;
### 2022-05-11 11:42:22.323
quit;
[anchu@localhost ~]$
```

### 测试数据

修改默认配置文件/etc/clickhouse-server/config.xml，支持远程访问

```shell
[anchu@localhost ~]$ su root
Password: 
[root@localhost anchu]# vi /etc/clickhouse-server/config.xml
[root@localhost anchu]# chmod u+w /etc/clickhouse-server/config.xml
[root@localhost anchu]# vi /etc/clickhouse-server/config.xml
#去掉注释
<listen_host>::</listen_host>
#或者 <listen_host>0.0.0.0</listen_host>
#重启
[anchu@localhost ~]$ su anchu
#注意启动方式
[anchu@localhost ~]$ 
 sudo clickhouse start
```

连接测试 (dbeaver或者clickhouse客户端均可)

![image-20220512174352795](文档图片/image-20220512174352795.png)

```shell
#默认用户 default 密码 clickhouse 默认库default
[anchu@localhost clickhouse]$ clickhouse-client --user=default --password=clickhouse -h 192.168.120.110 --port 9000 -m
ClickHouse client version 22.4.5.9 (official build).
Connecting to 192.168.120.110:9000 as user default.
Connected to ClickHouse server version 22.4.5 revision 54455.
localhost :) 


```





```
--创建clickhouse表，并指定引擎为mysql：
create table trade_store
(
id Int32,
name String,
createDate DateTime
)
engine = MySQL('127.0.0.1:3306', 'demo', 'trade_store', 'root', '123456');
```



#### (1)mysql表引擎使用（postgre引擎类似）

##### 1 应用

参考文档 ：

https://clickhouse.com/docs/zh/engines/database-engines/mysql

https://clickhouse.com/docs/zh/engines/database-engines/postgresql

https://www.cnblogs.com/MrYang-11-GetKnow/p/15901385.html

**官网描述：MySQL引擎用于将远程的MySQL服务器中的表映射到ClickHouse中，并允许您对表进行insert和select查询，以方便您在ClickHouse与MySQL之间进行数据交换。**
**MySQL数据库引擎会将对其的查询转换为MySQL语法并发送到MySQL服务器中，因此您可以执行诸如show tables或show create table之类的操作。**

ClickHouse使用mysql引擎可以与mysql数据库中的数据表建⽴映射，并通过SQL向其**发起远程查询或插入数据**，这是一个异步的过程，相当于ck起了一个线程专门用于同步mysql的数据到ck，主要在于同步mysql配置表的信息，因为配置表常有修改的需求，而ck并不擅长修改记录，且配置表的记录往往在几百条，配置表的同步往往是实时的，**目前针对小表数据使用，数据量大的表不建议使用**。

##### 2 语法规则

1）引擎定义：

```
CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]
(
name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1] [TTL expr1],
name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2] [TTL expr2],
...
) ENGINE = MySQL('host:port', 'database', 'table', 'user',
'password'[, replace_query, 'on_duplicate_clause']);
2）参数含义：
```

host： port表示MySQL的地址和端⼝。
database表示数据库的名称。
table表示需要映射的表名称。
user表示MySQL的⽤户名。
password表示MySQL的密码。
replace_query默认为0，对应MySQL的REPLACE INTO语法。如果将它设置为1，则会⽤REPLACE INTO代替INSERT INTO。
on_duplicate_clause默认为0，对应MySQL的ON DUPLICATE KEY语法。如果需要使⽤该设置，则必须将replace_query设置成0。

##### 3 示例

```sql
--创建一张mysql测试表：
CREATE TABLE `trade_store` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT 'id',
  `store_id` bigint(20) NOT NULL COMMENT '店铺id',
  `suppliers_id` bigint(20) NOT NULL COMMENT '商家id',
  `network_num` varchar(50) NOT NULL DEFAULT '' COMMENT '订单来了网络号',
  `im_identifier` varchar(50) DEFAULT '' COMMENT 'im注册id (store_自增id)暂时无用',
  `store_name` varchar(50) NOT NULL COMMENT '店铺名称',
  `head_pic` varchar(200) NOT NULL DEFAULT '0' COMMENT '店铺头像图片id',
  `sign_pic` varchar(300) DEFAULT '0' COMMENT '店铺招牌图片id',
  `store_type` tinyint(4) NOT NULL DEFAULT '0' COMMENT '店铺类型 1.农产品  2.名宿 3.景点  4.餐饮  ',
  `mobile` varchar(20) NOT NULL DEFAULT '' COMMENT '店铺联系手机号',
  `landline` varchar(20) NOT NULL DEFAULT '0' COMMENT '固话（暂时无用）',
  `coordinates` varchar(100) NOT NULL DEFAULT '' COMMENT '经纬度坐标',
  `latitude` varchar(255) NOT NULL DEFAULT '' COMMENT '纬度',
  `longitude` varchar(255) NOT NULL DEFAULT '' COMMENT '经度',
  `psite_id` bigint(20) NOT NULL DEFAULT '0' COMMENT '省级展馆id',
  `csite_id` bigint(20) NOT NULL DEFAULT '0' COMMENT '市级展馆id',
  `site_id` bigint(20) NOT NULL DEFAULT '0' COMMENT '区县展馆id（如果为省市级展馆 存0）',
  `real_site_id` bigint(20) NOT NULL DEFAULT '0' COMMENT '真实展馆id（省市区展馆中最低级展馆id）',
  `state` tinyint(1) NOT NULL DEFAULT '0' COMMENT '状态 0：启用，1：禁用',
  `stars` tinyint(2) NOT NULL DEFAULT '0' COMMENT '星级',
  `rooms` bigint(20) NOT NULL DEFAULT '0' COMMENT '房间数',
  `beds` bigint(20) NOT NULL DEFAULT '0' COMMENT '床位数',
  `seats` bigint(20) NOT NULL DEFAULT '0' COMMENT '餐位数',
  `features` varchar(150) NOT NULL DEFAULT '' COMMENT '服务特色',
  `store_star` float(10,2) DEFAULT '5.00' COMMENT '店铺平均评分',
  `service_star` float(10,2) DEFAULT '5.00' COMMENT '店铺服务平均评分',
  `goods_star` float(10,2) DEFAULT '5.00' COMMENT '店铺商品评价评分',
  `shipping_star` float(10,2) DEFAULT '5.00' COMMENT '店铺物流评价评分',
  `create_time` datetime DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `update_time` datetime DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  `project_code` varchar(50) NOT NULL DEFAULT '' COMMENT '登录端',
  PRIMARY KEY (`id`),
  UNIQUE KEY `un_store_id` (`store_id`),
  KEY `idx_suppliers_id` (`suppliers_id`)
) ENGINE=InnoDB AUTO_INCREMENT=31301 DEFAULT CHARSET=utf8mb4 COMMENT='商家店铺表'

-- 创建clickhouse表，并指定引擎为mysql：
create table trade_store
(
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT 'id',
  `store_id` bigint(20) NOT NULL COMMENT '店铺id',
  `suppliers_id` bigint(20) NOT NULL COMMENT '商家id',
  `network_num` varchar(50) NOT NULL DEFAULT '' COMMENT '订单来了网络号',
  `im_identifier` varchar(50) DEFAULT '' COMMENT 'im注册id (store_自增id)暂时无用',
  `store_name` varchar(50) NOT NULL COMMENT '店铺名称',
  `head_pic` varchar(200) NOT NULL DEFAULT '0' COMMENT '店铺头像图片id',
  `sign_pic` varchar(300) DEFAULT '0' COMMENT '店铺招牌图片id',
  `store_type` tinyint(4) NOT NULL DEFAULT '0' COMMENT '店铺类型 1.农产品  2.名宿 3.景点  4.餐饮  ',
  `mobile` varchar(20) NOT NULL DEFAULT '' COMMENT '店铺联系手机号',
  `landline` varchar(20) NOT NULL DEFAULT '0' COMMENT '固话（暂时无用）',
  `coordinates` varchar(100) NOT NULL DEFAULT '' COMMENT '经纬度坐标',
  `latitude` varchar(255) NOT NULL DEFAULT '' COMMENT '纬度',
  `longitude` varchar(255) NOT NULL DEFAULT '' COMMENT '经度',
  `psite_id` bigint(20) NOT NULL DEFAULT '0' COMMENT '省级展馆id',
  `csite_id` bigint(20) NOT NULL DEFAULT '0' COMMENT '市级展馆id',
  `site_id` bigint(20) NOT NULL DEFAULT '0' COMMENT '区县展馆id（如果为省市级展馆 存0）',
  `real_site_id` bigint(20) NOT NULL DEFAULT '0' COMMENT '真实展馆id（省市区展馆中最低级展馆id）',
  `state` tinyint(1) NOT NULL DEFAULT '0' COMMENT '状态 0：启用，1：禁用',
  `stars` tinyint(2) NOT NULL DEFAULT '0' COMMENT '星级',
  `rooms` bigint(20) NOT NULL DEFAULT '0' COMMENT '房间数',
  `beds` bigint(20) NOT NULL DEFAULT '0' COMMENT '床位数',
  `seats` bigint(20) NOT NULL DEFAULT '0' COMMENT '餐位数',
  `features` varchar(150) NOT NULL DEFAULT '' COMMENT '服务特色',
  `store_star` float(10,2) DEFAULT '5.00' COMMENT '店铺平均评分',
  `service_star` float(10,2) DEFAULT '5.00' COMMENT '店铺服务平均评分',
  `goods_star` float(10,2) DEFAULT '5.00' COMMENT '店铺商品评价评分',
  `shipping_star` float(10,2) DEFAULT '5.00' COMMENT '店铺物流评价评分',
  `create_time` datetime DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `update_time` datetime DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  `project_code` varchar(50) NOT NULL DEFAULT '' COMMENT '登录端'
)
engine = MySQL('192.168.120.110:3306', 'test', 'trade_store', 'root', '123456');
```

#####  4 总结

mysql引擎有点类似于 pg的FWD,会将请求转发给mysql，还是在mysql上执行，适合小表

FDW（Foreign Data Wrapper）是PostgreSQL（下文简称PG）中一项非常有意思的技术，通过它可以将PG变成一个通用的SQL引擎，使得用户可以通过SQL访问存储在PG之外的数据。

#### （2）SummingMergeTree引擎

##### 1 应用

参考文档：

https://clickhouse.com/docs/zh/engines/table-engines/mergetree-family/summingmergetree

该引擎继承自 [MergeTree](https://clickhouse.com/docs/zh/engines/table-engines/mergetree-family/mergetree)。区别在于，当合并 `SummingMergeTree` 表的数据片段时，**ClickHouse 会把所有具有相同主键的行合并为一行，该行包含了被合并的行中具有数值数据类型的列的汇总值（测试的时候批量导数据会很慢，可能就是这个原因）**。如果主键的组合方式使得单个键值对应于大量的行，则可以显著的减少存储空间并加快数据查询的速度。

我们推荐将该引擎和 `MergeTree` 一起使用。例如，在准备做报告的时候，将完整的数据存储在 `MergeTree` 表中，并且使用 `SummingMergeTree` 来存储聚合数据。这种方法可以使你避免因为使用不正确的主键组合方式而丢失有价值的数据。

##### 2 语法规则

1）引擎定义：

```
CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]
(
    name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1],
    name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2],
    ...
) ENGINE = SummingMergeTree([columns])
[PARTITION BY expr]
[ORDER BY expr]
[SAMPLE BY expr]
[SETTINGS name=value, ...]
```

##### 3 示例

```sql
-- 不能在mysql中创建，因为mysql库是通过MaterializeMySQL引擎创建，不支持创建在此引擎里面

-- Code: 48. DB::Exception: Received from 192.168.120.110:9000. DB::Exception: MaterializedMySQL database does not support CREATE TABLE. (NOT_IMPLEMENTED)

CREATE TABLE default.trade_order_sum
(
    `id` Int32 COMMENT '自增ID',
    `order_id` Int64 COMMENT '订单ID',
    `order_no` String COMMENT '订单编号',
    `user_id` Int64 COMMENT '用户ID',
    `supplier_id` Nullable(Int64) COMMENT '供应商ID',
    `supplier_name` Nullable(String) COMMENT '供应商名称',
    `store_image` Nullable(String) COMMENT '店铺头像',
    `store_id` Nullable(Int64) COMMENT '店铺ID',
    `store_name` Nullable(String) COMMENT '店铺名称',
    `order_from` Int8 COMMENT '订单来源 1：android 2:ios 3:小程序 4:H5 5:其他 6:线下',
    `order_type` Int8 COMMENT '订单类型 1农产品订单2民宿订单3旅游订单4景点订单5餐饮订单6拼团订单',
    `order_status` Int8 COMMENT '订单状态 1待支付 2待确认 3待成团 4待发货 5待使用 6待收货 7交易成功 8交易关闭',
    `pay_code` Nullable(String) COMMENT '支付编码（alipay，wechatpay,
 cloudflash）',
    `pay_name` Nullable(String) COMMENT '支付名称（支付宝支付，微信支付）',
    `pay_no` Nullable(String) COMMENT '支付单号',
    `pay_time` Nullable(DateTime) COMMENT '支付成功时间',
    `pay_send_time` Nullable(DateTime) COMMENT '支付上送时间',
    `receiver_name` Nullable(String) COMMENT '收件人名称',
    `mobile` Nullable(String) COMMENT '手机号',
    `province` Nullable(String) COMMENT '省',
    `city` Nullable(String) COMMENT '市',
    `district` Nullable(String) COMMENT '区',
    `town` Nullable(String) COMMENT '街道',
    `address` Nullable(String) COMMENT '详细地址',
    `last_shipping_time` Nullable(DateTime) COMMENT '最后发货时间',
    `total_amount` Nullable(Decimal(12,
 4)) COMMENT '货款合计',
    `post_fee` Nullable(Decimal(12,
 4)) COMMENT '邮费',
    `paymet` Nullable(Decimal(12,
 4)) COMMENT '应付金额',
    `discount_fee` Nullable(Decimal(12,
 4)) COMMENT '店铺优惠',
    `coupon_fee` Nullable(Decimal(12,
 4)) COMMENT '平台优惠',
    `prom_fee` Nullable(Decimal(14,
 4)) COMMENT '活动优惠',
    `accept_time` Nullable(DateTime) COMMENT '接单时间',
    `seller_memo` Nullable(String) COMMENT '卖家备注',
    `buyer_momo` Nullable(String) COMMENT '买家备注',
    `confirm_time` Nullable(DateTime) COMMENT '确认收货时间',
    `shipping_type` Int8 COMMENT '配送方式1快递2同城配送3自提',
    `order_commit_id` String COMMENT '订单提交ID，用于拆分订单展示',
    `team_id` Nullable(Int64) COMMENT '拼团团队id',
    `pick_template_id` Nullable(Int32) COMMENT '自提id',
    `is_delete` Nullable(Int8) COMMENT '删除标记',
    `update_time` Nullable(DateTime) COMMENT '更新时间',
    `create_time` Nullable(DateTime) COMMENT '创建时间',
    `project_code` Nullable(String) COMMENT '项目编码',
    `cancel_reason` Nullable(Int32) COMMENT '订单取消原因(1、手动取消 2、超时自动取消 3、拒绝接单 4、超时未接单 5、)',
    `join_from` Nullable(String) COMMENT '加购来源',
    `is_settlement` Nullable(Int8) COMMENT '是否结算',
    `is_system` Nullable(Int8) COMMENT '是否系统生成 0否1是',
    `outer_order_no` Nullable(String) COMMENT '外部订单号，用于第三方',
    `_sign` Int8 MATERIALIZED 1,
    `_version` UInt64 MATERIALIZED 1,
    INDEX _version _version TYPE minmax GRANULARITY 1
)
ENGINE = SummingMergeTree(_version)
PARTITION BY intDiv(id,
 4294967)
ORDER BY (id)
SETTINGS index_granularity = 8192


-- 查看创建表
localhost :) use default;

localhost :)  show tables;

┌─name────────────┐
│ trade_order_sum │
└─────────────────┘ 

localhost :) 


SELECT
                                      sum(o.total_amount + o.post_fee) AS gmv,
                                      sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount
                                  FROM
                                      trade_order_sum o;
-- 查询所有商家GMV统计和销售额                                      
localhost :) SELECT
                                      sum(o.total_amount + o.post_fee) AS gmv,
                                      sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount
                                  FROM
                                      trade_order_sum o;
                                      
                                      
 -- 获取所有商家每年 销售额和GMV
 with formatDateTime(create_time,'%Y') as year  
select year,sum(o.total_amount + o.post_fee) AS gmv,sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount  from trade_order_sum o
group by year order by year asc;


 
-- 获取所有商家每年每月 销售额和GMV 

select formatDateTime(create_time,'%Y') as year ,formatDateTime(create_time,'%m') as month,sum(o.total_amount + o.post_fee) as gmv,sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount,count(o.id) AS ordercounts  from trade_order_sum o   group by year,month

-- 获取所有商家今年每月 销售额和GMV
   
select  formatDateTime(now(),'%Y') as year ,formatDateTime(create_time,'%m') as month,sum(o.total_amount + o.post_fee) as gmv,sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount,count(o.id) AS ordercounts  from trade_order_sum o  where formatDateTime(create_time,'%Y')=year  group by month

-- 获取所有商家今年当月 销售额和GMV
   
select  formatDateTime(now(),'%Y-%m') as nowmonth,sum(o.total_amount + o.post_fee) as gmv,sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount,count(o.id) AS ordercounts  from trade_order_sum o  where formatDateTime(create_time,'%Y-%m')=nowmonth

-- 获取所有商家一段时间内的 销售额和GMV
with timeRange as( select toDateTime('2022-04-01 00:00:00') AS startTime,toDateTime('2022-04-30 23:59:59') AS endTime)

select  sum(o.total_amount + o.post_fee) as gmv,sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount,count(o.id) AS ordercounts  from trade_order_sum o,timeRange where o.create_time>=timeRange.startTime and o.create_time<=endTime
                                    
```

##### 4 总结

查询统计快，初始化数据慢

#### （3）MaterializeMySQL引擎

##### 1 应用

参考文档

https://clickhouse.com/docs/zh/engines/database-engines/materialized-mysql

https://clickhouse.com/docs/en/engines/database-engines/materialized-mysql

https://blog.csdn.net/zhangcongyi420/article/details/122763198

https://mp.weixin.qq.com/s?__biz=Mzg5NTY2NTE1NQ==&mid=2247489252&idx=2&sn=5b2bf18a41d0c459aaa2dea7514c345c&chksm=c00d8388f77a0a9e16f399ed02c3eb886d5fbefec84297748aff83d6feced91d761f0f88b087#rd

https://www.cnblogs.com/MrYang-11-GetKnow/p/16051021.html

https://cdn.modb.pro/db/49058

clickhouse 20.8将新增 MaterializeMySQL引擎 ,可通过binlog日志实时物化mysql数据，极大提升了数仓的查询性能和数据同步的时效性；原有mysql中承担的数据分析工作 可交由clickhouse去做，这么做可显著降低线上mysql的负载，从此OLTP与OLAP业务实现完美融合。

**1.1 特点**

　　（1）MaterializeMySQL 同时支持全量和增量同步，在 database 创建之初会全量同步MySQL 中的表和数据，之后则会通过 binlog 进行增量同步。

　　（2）MaterializeMySQL database 为其所创建的每张 ReplacingMergeTree 自动增加了_sign 和 _version 字段。

　　其中，_version 用作 ReplacingMergeTree 的 ver 版本参数，每当监听到 insert、update和 delete 事件时，在 databse 内全局自增。而 _sign 则用于标记是否被删除，取值 1 或

者 -1。

　　目前 MaterializeMySQL 支持如下几种 binlog 事件:

　　➢MYSQL_WRITE_ROWS_EVENT:_sign = 1，_version ++

　　➢MYSQL_DELETE_ROWS_EVENT:_sign = -1，_version ++

　　➢MYSQL_UPDATE_ROWS_EVENT:新数据 _sign = 1

　　➢MYSQL_QUERY_EVENT: 支持 CREATE TABLE 、DROP TABLE 、RENAME TABLE 等。

　　即支持mysql 5.6/5.7/8.0版本数据库，兼容insert，update，delete，alter，create，drop，truncate等大部分DDL操作。

**1.2.使用细则**

（1）DDL 查询

　　MySQL DDL 查询被转换成相应的 ClickHouse DDL 查询（ALTER, CREATE, DROP, RENAME）。如果 ClickHouse 不能解析某些 DDL 查询，该查询将被忽略。

（2）数据复制

　　MaterializeMySQL 不支持直接插入、删除和更新查询，而是将 DDL 语句进行相应转换：

　　①MySQL INSERT 查询被转换为 INSERT with _sign=1。

　　②MySQL DELETE 查询被转换为 INSERT with _sign=-1。

　　③MySQL UPDATE 查询被转换成 INSERT with _sign=1 和 INSERT with _sign=-1。

　　即使用`MaterializedMySQL`数据库引擎时，ReplacingMergeTree表与虚拟`_sign`和`_version`列一起使用。

- `_version`— 交易计数器。键入UInt64。
- `_sign`— 删除标记。键入Int8。可能的值：
  - `1`— 未删除行，
  - `-1`— 行被删除。

（3）SELECT 查询

　　如果在 SELECT 查询中没有指定_version，则使用 FINAL 修饰符，返回_version 的最大值对应的数据，即最新版本的数据。

　　如果在 SELECT 查询中没有指定_sign，则默认使用 WHERE _sign=1，即返回未删除状态（_sign=1)的数据。

（4）索引转换

　　ClickHouse 数据库表会自动将 MySQL 主键和索引子句转换为 ORDER BY 元组。

　　ClickHouse 只有一个物理顺序，由 ORDER BY 子句决定。如果需要创建新的物理顺序，请使用物化视图。

- `_sign=-1`没有从表中物理删除的行。
- `UPDATE/DELETE`引擎不支持级联查询`MaterializedMySQL`，因为它们在 MySQL 二进制日志中不可见。
- 复制很容易被破坏。
- 禁止对数据库和表进行手动操作。
- `MaterializedMySQL`受optimize_on_insert 设置影响。`MaterializedMySQL`当 MySQL 服务器中的表发生变化时，数据会合并到数据库中的相应表中。

（5）类型转换

| MySQL                 | ClickHouse  |
| --------------------- | ----------- |
| TINY                  | Int8        |
| SHORT                 | Int16       |
| INT24                 | Int32       |
| LONG                  | UInt32      |
| LONGLONG              | UInt64      |
| FLOAT                 | Float32     |
| DOUBLE                | Float64     |
| DECIMAL, NEWDECIMAL   | Decimal     |
| DATE, NEWDATE         | Date32      |
| DATETIME, TIMESTAMP   | DateTime    |
| DATETIME2, TIMESTAMP2 | DateTime64  |
| YEAR                  | UInt16      |
| TIME                  | Int64       |
| ENUM                  | Enum        |
| STRING                | String      |
| VARCHAR, VAR_STRING   | String      |
| BLOB                  | String      |
| GEOMETRY              | String      |
| BINARY                | FixedString |
| BIT                   | UInt64      |
| SET                   | UInt64      |

##### 2 语法规则

```
CREATE DATABASE [IF NOT EXISTS] db_name [ON CLUSTER cluster]
ENGINE = MaterializedMySQL('host:port', ['database' | database], 'user', 'password') [SETTINGS ...]
[TABLE OVERRIDE table1 (...), TABLE OVERRIDE table2 (...)]
```

**引擎参数**

- `host:port` — MySQL 服务地址.
- `database` — MySQL 数据库名称.
- `user` — MySQL 用户名.
- `password` — MySQL 用户密码.

**引擎配置**

- `max_rows_in_buffer` — 允许在内存中缓存数据的最大行数(对于单个表和无法查询的缓存数据)。当超过这个数字时，数据将被物化。默认值:`65 505`。
- `max_bytes_in_buffer` - 允许在内存中缓存数据的最大字节数(对于单个表和无法查询的缓存数据)。当超过这个数字时，数据将被物化。默认值: `1 048 576 `。
- `max_rows_in_buffers` - 允许在内存中缓存数据的最大行数(用于数据库和无法查询的缓存数据)。当超过这个数字时，数据将被物化。默认值: `65 505`。
- `max_bytes_in_buffers` - 允许在内存中缓存数据的最大字节数(用于数据库和无法查询的缓存数据)。当超过这个数字时，数据将被物化。默认值: `1 048 576`。
- `max_flush_data_time `- 允许数据在内存中缓存的最大毫秒数(对于数据库和无法查询的缓存数据)。当超过这个时间，数据将被物化。默认值: `1000`。
- `max_wait_time_when_mysql_unavailable` - MySQL不可用时的重试间隔(毫秒)。负值禁用重试。默认值:`1000`。 — `allows_query_when_mysql_lost `—允许在MySQL丢失时查询物化表。默认值:`0`(`false`)。
- `allows_query_when_mysql_lost` — ‎允许在MySQL丢失时查询实例化表. 默认值: `0` (`false`).
- `materialized_mysql_tables_list` 以逗号分隔的mysql数据库表列表，该列表将由MaterializedMySQL数据库引擎复制。默认值：空列表 — 表示将复制整个表‎.

##### 3 示例

```sql
CREATE DATABASE mysql ENGINE = MaterializedMySQL('192.168.120.110:3306', 'test', 'user', '123456')
     SETTINGS
        allows_query_when_mysql_lost=true,
        max_wait_time_when_mysql_unavailable=10000,
        materialized_mysql_tables_list=trade_order,trade_store;
        
        
      
```

**报错1**：Enable allow_experimental_database_materialized_mysql to use it.. (UNKNOWN_DATABASE_ENGINE)  需要配置：allow_experimental_database_materialized_mysql 

![image-20220513101839955](文档图片/image-20220513101839955.png)

配置如下：

```sql
[anchu@localhost ~]$ clickhouse-client --user=default --password=clickhouse -h 192.168.120.110 --port 9000 -m

localhost :) SET allow_experimental_database_materialized_mysql = 1;

localhost :) show SETTINGS  like '%allow_experimental_database_materialized_mysql%';

SHOW SETTINGS LIKE '%allow_experimental_database_materialized_mysql%'

Query id: 5688f74f-dde6-47e9-9fc3-52501d173ad2

┌─name───────────────────────────────────────────┬─type─┬─value─┐
│ allow_experimental_database_materialized_mysql │ Bool │ 1     │


localhost :) CREATE DATABASE test ENGINE = MaterializedMySQL('192.168.120.110:3306', 'test', 'user', '123456')
                  SETTINGS
                     include_tables ='test';

CREATE DATABASE test
ENGINE = MaterializedMySQL('192.168.120.110:3306', 'test', 'user', '123456')
SETTINGS include_tables = 'test'

Query id: 7dab5817-9e89-40dc-b8a3-8a5776b4a39f

0 rows in set. Elapsed: 0.026 sec. 
Received exception from server (version 22.4.5):
Code: 501. DB::Exception: Received from 192.168.120.110:9000. DB::Exception: Cannot create MySQL database, because Code: 115. DB::Exception: Unknown setting include_tables: for database MaterializedMySQL. (UNKNOWN_SETTING),. (CANNOT_CREATE_DATABASE)

localhost :)CREATE DATABASE mysql ENGINE = MaterializedMySQL('192.168.120.110:3306', 'test', 'user', '123456')
                  SETTINGS
                     allows_query_when_mysql_lost=true,
                     max_wait_time_when_mysql_unavailable=10000,
                     materialized_mysql_tables_list='TEST';

```

**报错2**：MySQL SYNC USER ACCESS ERR: mysql sync user needs at least GLOBAL PRIVILEGES:'RELOAD, REPLICATION SLAVE, REPLICATION CLIENT' and SELECT PRIVILEGE on Database test.   需要当前用户有REPLICATION SLAVE权限

![image-20220513104142113](文档图片/image-20220513104142113.png)

参考文档：https://cdn.modb.pro/db/49058

- 创建用户
- 全局赋予 replication client,replication slave, reload 权限
- 对同步库 test 赋予 select 权限

```sql
-- mysql中创建用户,并赋予权限
[anchu@localhost ~]$ mysql -u root -P 3306 -h 192.168.120.110  -p
Enter password: 
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 98
Server version: 5.7.24-log MySQL Community Server (GPL)
mysql>  CREATE USER 'clickhouse'@'%' IDENTIFIED BY 'clickhouse';
Query OK, 0 rows affected (0.08 sec)

mysql> GRANT select ON test.* TO 'clickhouse'@'%';   -- 注意库名test
Query OK, 0 rows affected (0.01 sec)

mysql> GRANT  replication client,replication slave, reload on *.* to 'clickhouse'@'%';
Query OK, 0 rows affected (0.00 sec)

mysql> FLUSH PRIVILEGES;
Query OK, 0 rows affected (0.01 sec)

mysql> 


-- clickhouse 继续创建索引，切换为clickhouse用户

clickhouse-client --user=default --password=clickhouse -h 192.168.120.110 --port 9000 -m

localhost :) SET allow_experimental_database_materialized_mysql = 1; -- 会话层面，需要改在配置文件里

Query id: a7aeef05-f7c7-4fa7-b14c-b0a8eeb658db

Ok.

localhost :)  CREATE DATABASE mysql ENGINE = MaterializedMySQL('192.168.120.110:3306', 'test', 'clickhouse', 'clickhouse')
                               SETTINGS
                                  allows_query_when_mysql_lost=true,
                                  max_wait_time_when_mysql_unavailable=10000,
                                  materialized_mysql_tables_list='test';

CREATE DATABASE mysql
ENGINE = MaterializedMySQL('192.168.120.110:3306', 'test', 'clickhouse', 'clickhouse')
SETTINGS allows_query_when_mysql_lost = 1, max_wait_time_when_mysql_unavailable = 10000, materialized_mysql_tables_list = 'test'

Query id: fbb7b97d-f992-454c-a4d2-9a855b23c501

Ok.

0 rows in set. Elapsed: 0.056 sec. 


--查看数据库mysql
localhost :) show databases;

SHOW DATABASES

Query id: 9926a02d-1d4d-4a13-9aaa-68f320e5763a

┌─name───────────────┐
│ INFORMATION_SCHEMA │
│ default            │
│ information_schema │
│ mysql              │
│ system             │
└────────────────────┘

5 rows in set. Elapsed: 0.003 sec. 

localhost :) use mysql;


localhost :) show tables;  


localhost :) 
```

 **报错3**：没有同步到表，原因是必须有主键；

```sql
-- clickhouse 删除之前创建的mysql库
localhost :) drop database mysql;
localhost :)  CREATE DATABASE mysql ENGINE = MaterializedMySQL('192.168.120.110:3306', 'test', 'clickhouse', 'clickhouse')
                               SETTINGS
                                  allows_query_when_mysql_lost=true,
                                  max_wait_time_when_mysql_unavailable=10000,
                                  materialized_mysql_tables_list='trade_store,trade_order';

localhost :) use mysql;
localhost :) show tables;

SHOW TABLES

Query id: 4f33e86c-0e93-4c8a-913f-4dccd4bb179d

┌─name────────┐
│ trade_order │
│ trade_store │
└─────────────┘


localhost :) select * from trade_store limit 1;

SELECT *
FROM trade_store
LIMIT 1

Query id: e6e56f04-fea2-493b-aa7a-19c981eb7846

┌─id─┬─store_id─┬─suppliers_id─┬─network_num─┬─im_identifier─┬─store_name───┬─head_pic───────────────────────────────────────────────────────────────┬─sign_pic──────────────────────────────────────────────────────────────────┬─store_type─┬─mobile──────┬─landline─┬─coordinates─┬─latitude─┬─longitude─┬──────────psite_id─┬──────────csite_id─┬─site_id─┬─real_site_id─┬─state─┬─stars─┬─rooms─┬─beds─┬─seats─┬─features─┬─store_star─┬─service_star─┬─goods_star─┬─shipping_star─┬─────────create_time─┬─────────update_time─┬─project_code─┐
│  1 │        1 │            1 │             │               │ 网上农博测试 │ https://nb-img.hzanchu.com/acimg/3564e3565e8bd1bc3bb7418a8f24c24d.jpeg │ https://wsnbh-img.hzanchu.com/acimg/3e7d4729d601b160497836a0ee381a17.jpeg │          0 │ 17716256898 │ 0        │             │          │           │ 43657283580821504 │ 43657508412293120 │     112 │          112 │     0 │     0 │     0 │    0 │     0 │          │          5 │            5 │          5 │             5 │ 2019-11-13 11:31:07 │ 2022-04-25 18:51:30 │ 3300         │
└────┴──────────┴──────────────┴─────────────┴───────────────┴──────────────┴────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────┴────────────┴─────────────┴──────────┴─────────────┴──────────┴───────────┴───────────────────┴───────────────────┴─────────┴──────────────┴───────┴───────┴───────┴──────┴───────┴──────────┴────────────┴──────────────┴────────────┴───────────────┴─────────────────────┴─────────────────────┴──────────────┘

1 rows in set. Elapsed: 0.012 sec. Processed 5.39 thousand rows, 2.16 MB (468.51 thousand rows/s., 187.57 MB/s.)



```

**对比统计** select sum(post_fee+paymet) from trade_order 查看订单GMV，销售额统计;

```sql
-- clickhouse 查看订单GMV

localhost :) select sum(post_fee+paymet) from trade_order;
┌─sum(plus(post_fee, paymet))─┐
│                256190863.32 │
└─────────────────────────────┘
→ Progress: 2.09 million rows, 488.26 MB (585.99 thousand rows/s., 137.02 MB/s.) ██████████████████████ ↘ Progress: 2.09 million rows, 488.81 MB (586.64 thousand rows/s., 137.17 MB/s.) ██████████████████████↓ Progress: 2.09 million rows, 488.81 MB (586.63 thousand rows/s., 137.17 MB/s.) ██████████████████████

1 rows in set. Elapsed: 3.563 sec. Processed 2.09 million rows, 488.81 MB (586.63 thousand rows/s., 137.17 MB/s.)

localhost :) select sum(post_fee+paymet) from trade_order;



-- mysql 查看订单GMV
mysql> select sum(post_fee+paymet) from trade_order;
+----------------------+
| sum(post_fee+paymet) |
+----------------------+
|       256190863.3200 |
+----------------------+
1 row in set (6.26 sec)
```

![image-20220513113648215](文档图片/image-20220513113648215.png)



```sql

-- 分别在mysql 和clickhouse中执行以下操作 获取商家销售额和GMV：
SELECT
                         o.supplier_id AS supplierId,
                         o.store_id AS storeId,
                         sum(o.total_amount + o.post_fee) AS gmv,
                         sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount
                     FROM
                         trade_order o 
 group by o.supplier_id,o.store_id;

                     
-- 项目中查询gmv和销售额            
SELECT
            o.order_id AS orderId,
            o.supplier_id AS supplierId,
            o.store_id AS storeId,
            sum(o.total_amount + o.post_fee) AS gmv,
            sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount,
            o.order_status AS orderStatus,
            o.cancel_reason as cancelReason,
            o.pay_time as payTime,
            o.project_code as projectCode
        FROM
            trade_order o            
        WHERE o.create_time >="2022-04-01 00:00:00" and o.create_time <="2022-04-30 23:59:59"
        and o.is_system = 0
        GROUP BY
            o.order_id
```

![image-20220513135255382](文档图片/image-20220513135255382.png)

```sql
-- 获取所有商家销售额和GMV
SELECT
                         sum(o.total_amount + o.post_fee) AS gmv,
                         sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount
                     FROM
                         trade_order o;
```

![image-20220513141040233](文档图片/image-20220513141040233.png)



其他查询

```sql
 -- 获取每个商家每天的销售额和GMV 
 SELECT
                         o.supplier_id AS supplierId,
                         o.store_id AS storeId,
                         sum(o.total_amount + o.post_fee) AS gmv,
                         sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount,
                         toStartOfDay(o.create_time) as timeInterval
                     FROM
                         trade_order o 
         group by o.supplier_id,o.store_id,toStartOfDay(o.create_time);
         
 -- 获取所有商家每天的销售额和GMV
  SELECT

                         sum(o.total_amount + o.post_fee) AS gmv,
                         sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount,
                         toStartOfDay(o.create_time) as timeInterval
                     FROM
                         trade_order o 
         group by toStartOfDay(o.create_time);
 -- 获取所有商家今天的销售额和GMV  ????
  SELECT

                         sum(o.total_amount + o.post_fee) AS gmv,
                         sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount,
                         toStartOfDay(create_time) as timeInterval
                     FROM
                         trade_order o 
                         where toStartOfDay(create_time)
 
  -- 获取所有商家大于某个时间点的 销售额和GMV
  with formatDateTime(create_time,'%H') as hour
select sum(o.total_amount + o.post_fee) AS gmv,sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount  from trade_order o  where hour>'10' and hour<'12'
;

 -- 获取所有商家每月(每年都统计)大于某个时间点的 销售额和GMV
   with ( select formatDateTime(now(),'%H') as hour,formatDateTime(now(),'%m') as month) as timeInterval

 with formatDateTime(create_time,'%H') as hour  
select formatDateTime(create_time,'%m') as month,sum(o.total_amount + o.post_fee) AS gmv,sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount  from trade_order o  where hour>'10' and hour<'12'
group by month order by month asc;

-- 获取所有商家每年 销售额和GMV
 with formatDateTime(create_time,'%Y') as year  
select year,sum(o.total_amount + o.post_fee) AS gmv,sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount  from trade_order o
group by year order by year asc;

-- with语句
with timeInterval as (select formatDateTime(create_time,'%Y') as year ,formatDateTime(create_time,'%m') as month from trade_order group by year,month) 
   
-- 获取所有商家每年每月 销售额和GMV 

select formatDateTime(create_time,'%Y') as year ,formatDateTime(create_time,'%m') as month,sum(o.total_amount + o.post_fee) as gmv,sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount,count(o.id) AS ordercounts  from trade_order o   group by year,month

-- 获取所有商家今年每月 销售额和GMV
   
select  formatDateTime(now(),'%Y') as year ,formatDateTime(create_time,'%m') as month,sum(o.total_amount + o.post_fee) as gmv,sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount,count(o.id) AS ordercounts  from trade_order o  where formatDateTime(create_time,'%Y')=year  group by month

-- 获取所有商家今年当月 销售额和GMV
   
select  formatDateTime(now(),'%Y-%m') as nowmonth,sum(o.total_amount + o.post_fee) as gmv,sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount,count(o.id) AS ordercounts  from trade_order o  where formatDateTime(create_time,'%Y-%m')=nowmonth

-- 获取所有商家一段时间内的 销售额和GMV
with timeRange as( select toDateTime('2022-04-01 00:00:00') AS startTime,toDateTime('2022-04-30 23:59:59') AS endTime)

select  sum(o.total_amount + o.post_fee) as gmv,sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount,count(o.id) AS ordercounts  from trade_order o,timeRange where o.create_time>=timeRange.startTime and o.create_time<=endTime
```

参考文档：

https://blog.csdn.net/u011228841/article/details/97235746

Modifier	Description	Example
%C	year divided by 100 and truncated to integer (00-99)	20
%d	day of the month, zero-padded (01-31)	02
%D	Short MM/DD/YY date, equivalent to %m/%d/%y	01/02/2018
%e	day of the month, space-padded ( 1-31)	2
%F	short YYYY-MM-DD date, equivalent to %Y-%m-%d	2018-01-02
%H	hour in 24h format (00-23)	22
%I	hour in 12h format (01-12)	10
%j	day of the year (001-366)	002
%m	month as a decimal number (01-12)	01
%M	minute (00-59)	33
%n	new-line character ('\n')	 
%p	AM or PM designation	PM
%R	24-hour HH:MM time, equivalent to %H:%M	22:33
%S	second (00-59)	44
%t	horizontal-tab character ('\t')	 
%T	ISO 8601 time format (HH:MM:SS), equivalent to %H:%M:%S	22:33:44
%u	ISO 8601 weekday as number with Monday as 1 (1-7)	2
%V	ISO 8601 week number (01-53)	01
%w	weekday as a decimal number with Sunday as 0 (0-6)	2
%y	Year, last two digits (00-99)	18
%Y	Year	2018
%%	a % sign	%

##### 4总结

查询统计慢一些，同步数据快



##### 5优化 混搭模式-物化视图优化 

**MaterializeMySQL引擎同步数据，物化视图SummingMergeTree引擎查询统计**

-- 由于MaterializeMySQL引擎初始化数据快,但是查询慢
-- SummingMergeTree初始化数据慢，查询快
-- 可以基于MaterializeMySQL引擎创建新表SummingMergeTree引擎的 先做每个订单的统计物化视图

参考文档：

https://blog.csdn.net/weixin_44080445/article/details/119780193

https://cloud.tencent.com/developer/article/1988528



```sql
localhost :) CREATE MATERIALIZED VIEW trade_order_view
             ENGINE=SummingMergeTree
             -- PARTITION BY (date) ORDER BY (date)
             -- ORDER BY (date)
             PARTITION BY intDiv(id,4294967) ORDER BY (id)
             AS SELECT 
             o.id,
             o.order_id,
             o.order_no,
             formatDateTime(create_time,'%F') as date,
             sum(o.total_amount + o.post_fee) as gmv,
             sum(o.paymet + o.discount_fee + o.coupon_fee) AS salesAmount
             from mysql.trade_order o   
             group by o.id,o.order_id,o.order_no,date
             order by id asc;

-- 由于MaterializeMySQL引擎初始化数据快,但是查询慢
-- SummingMergeTree初始化数据慢，查询快
-- 可以基于MaterializeMySQL引擎创建新表SummingMergeTree引擎的 先做每个订单的统计物化视图

----------------------创建物化视图--------------------------
CREATE MATERIALIZED VIEW trade_order_view
ENGINE = SummingMergeTree
PARTITION BY intDiv(id, 4294967)
ORDER BY id AS
SELECT
    o.id,
    o.order_id,
    o.order_no,
    formatDateTime(create_time, '%F') AS date,
    sum(o.total_amount + o.post_fee) AS gmv,
    sum((o.paymet + o.discount_fee) + o.coupon_fee) AS salesAmount
FROM mysql.trade_order AS o
GROUP BY
    o.id,
    o.order_id,
    o.order_no,
    date
ORDER BY id ASC

localhost :) show tables;
SHOW TABLES
Query id: 85218a64-bfff-4555-876d-e5017c324ee4

┌─name───────────────────────────────────────────┐
│ .inner_id.f5cf465c-49b2-487d-b614-afc592178793 │
│ trade_order_sum                                │
│ trade_order_view                               │
└────────────────────────────────────────────
----------------------创建物化视图--------------------------
----------------------查询物化视图--------------------------
 select  o.date,sum(o.gmv) as gmv,sum(o.salesAmount) AS salesAmount,count(o.salesAmount) AS ordercounts  from  trade_order_view o group by o.date
 
 0 rows in set. Elapsed: 0.301 sec.  --没有数据
----------------------查询物化视图--------------------------


--问题1： MaterializeMySQL引擎不支持DDL
Received exception from server (version 22.4.5):
Code: 48. DB::Exception: Received from 192.168.120.110:9000. DB::Exception: MaterializedMySQL database does not support CREATE TABLE. (NOT_IMPLEMENTED)

--问题2：order 和分区键，主键不为空
Code: 44. DB::Exception: Received from 192.168.120.110:9000. DB::Exception: Sorting key contains nullable columns, but `setting allow_nullable_key` is disabled. (ILLEGAL_COLUMN)
-- 问题3：order 和分区键，主键不为空并且是必需的
Code: 42. DB::Exception: Received from 192.168.120.110:9000. DB::Exception: ORDER BY or PRIMARY KEY clause is missing. Consider using extended storage definition syntax with ORDER BY or PRIMARY KEY clause. With deprecated old syntax (highly not recommended) storage SummingMergeTree requires 3 to 5 parameters: 

-- 问题4：物化视图创建完，会有 .inner_id.f5cf465c-49b2-487d-b614-afc592178793 ，持久化物化视图数据的表，可以查询和视图结果一样
localhost :) select * from `.inner_id.f5cf465c-49b2-487d-b614-afc592178793`;
localhost :) select * from trade_order_view;
 0 rows in set. Elapsed: 0.301 sec.  --没有数据
-- 问题5：物化视图默认不同步数据，需配置参数 POPULATE,删除视图，重新创建如下
drop view trade_order_view;

----------------------创建物化视图，并初始化数据--------------------------
CREATE MATERIALIZED VIEW trade_order_view
ENGINE = SummingMergeTree
PARTITION BY intDiv(id, 4294967)
ORDER BY id 
POPULATE AS
SELECT
    o.id,
    o.order_id,
    o.order_no,
    formatDateTime(create_time, '%F') AS date,
    sum(o.total_amount + o.post_fee) AS gmv,
    sum((o.paymet + o.discount_fee) + o.coupon_fee) AS salesAmount
FROM mysql.trade_order AS o
GROUP BY
    o.id,
    o.order_id,
    o.order_no,
    date
ORDER BY id ASC

----------------------创建物化视图，并初始化数据--------------------------
----------------------查询物化视图--------------------------
 select  o.date,sum(o.gmv) as gmv,sum(o.salesAmount) AS salesAmount,count(o.salesAmount) AS ordercounts  from  trade_order_view o 
 
Query id: 4d58ce64-f43b-4d34-9a03-15fdd4b48d0c

┌──────────gmv─┬──salesAmount─┬─ordercounts─┐
│ 322998710.02 │ 298196356.85 │     2090450 │
└──────────────┴──────────────┴─────────────┘
----------------------查询物化视图--------------------------
```



### （4）

基于Clickhouse的日志体系

https://cloud.tencent.com/developer/article/1932184

https://zhuanlan.zhihu.com/p/103781296



| 编号                     | 事件名称                                                     | 包含属性              | 属性定义 | 属性值类型 |
| ------------------------ | ------------------------------------------------------------ | --------------------- | -------- | ---------- |
| 1                        | 内容浏览                                                     | 用户ID                |          |            |
| 访客ID                   |                                                              |                       |          |            |
| 时间                     | 行为发生时间                                                 |                       |          |            |
| IP                       |                                                              |                       |          |            |
| 区域地点（IP解析省市区） |                                                              |                       |          |            |
| GPS 经纬度               |                                                              |                       |          |            |
| GPS定位地址（省市区）    |                                                              |                       |          |            |
| 网络环境                 | 4G，Wi-Fi                                                    |                       |          |            |
| 操作系统                 | IOS13                                                        |                       |          |            |
| 浏览器型号版本           | H5                                                           | H5内嵌到小程序和APP？ |          |            |
| APP版本                  | 1: IOS 2.1     2: Androids 2.0                               |                       |          |            |
| 微信小程序               | 1:农博小程序     2:鱼米之乡小程序     3:余杭小程序     4:金峨缘小程序 |                       |          |            |
| 设备唯一编码             | 小程序：openID     APP：设备码     H5: cookie                |                       |          |            |
| 浏览内容类型             | 1：活动专题页     2: 直播     3: 商品详情     4: 购物车     5: 搜索     6:首页     7: 其它固定页面 |                       |          |            |
| 浏览内容                 | 1: 专题页编号     2:直播房间号     3:商品编号                |                       |          |            |
| 三方浏览渠道             | 1:联通     2:云闪付     3:市民卡     4:微信分享     5:微信朋友圈     6: 外部广告推广 |                       |          |            |
| 三方浏览触点来源         | 1: 联通APP轮播     2: 联通小程序轮播     3:联通H5 轮播     4: 联通APP广告位 |                       |          |            |
| 上级页面refer来源        | spm,拆开                                                     |                       |          |            |
| 页面停留时常             |                                                              |                       |          |            |
| create_time              |                                                              |                       |          |            |
|                          | 抢券                                                         |                       |          |            |
|                          | 分享                                                         |                       |          |            |
|                          | 收藏                                                         |                       |          |            |

















## 4.3  clickhouse+mybatis集成

```
/******************************************/
/*   DatabaseName = ck_actrade_online   */
/*   TableName = trade_order   */
/******************************************/
CREATE TABLE ck_actrade_online.trade_order (`id` Int32 COMMENT '自增ID', `order_id` Int64 COMMENT '订单ID', `order_no` String COMMENT '订单编号', `user_id` Int64 COMMENT '用户ID', `supplier_id` Nullable(Int64) COMMENT '供应商ID', `supplier_name` Nullable(String) COMMENT '供应商名称', `store_image` Nullable(String) COMMENT '店铺头像', `store_id` Nullable(Int64) COMMENT '店铺ID', `store_name` Nullable(String) COMMENT '店铺名称', `order_from` Int8 COMMENT '订单来源 1：android 2:ios 3:小程序 4:H5 5:其他 6:线下', `order_type` Int8 COMMENT '订单类型 1农产品订单2民宿订单3旅游订单4景点订单5餐饮订单6拼团订单', `order_status` Int8 COMMENT '订单状态 1待支付 2待确认 3待成团 4待发货 5待使用 6待收货 7交易成功 8交易关闭', `pay_code` Nullable(String) COMMENT '支付编码（alipay，wechatpay, cloudflash）', `pay_name` Nullable(String) COMMENT '支付名称（支付宝支付，微信支付）', `pay_no` Nullable(String) COMMENT '支付单号', `pay_time` Nullable(DateTime) COMMENT '支付成功时间', `pay_send_time` Nullable(DateTime) COMMENT '支付上送时间', `receiver_name` Nullable(String) COMMENT '收件人名称', `mobile` Nullable(String) COMMENT '手机号', `province` Nullable(String) COMMENT '省', `city` Nullable(String) COMMENT '市', `district` Nullable(String) COMMENT '区', `town` Nullable(String) COMMENT '街道', `address` Nullable(String) COMMENT '详细地址', `last_shipping_time` Nullable(DateTime) COMMENT '最后发货时间', `total_amount` Nullable(Decimal(12, 4)) COMMENT '货款合计', `post_fee` Nullable(Decimal(12, 4)) COMMENT '邮费', `paymet` Nullable(Decimal(12, 4)) COMMENT '应付金额', `discount_fee` Nullable(Decimal(12, 4)) COMMENT '店铺优惠', `coupon_fee` Nullable(Decimal(12, 4)) COMMENT '平台优惠', `prom_fee` Nullable(Decimal(14, 4)) COMMENT '活动优惠', `accept_time` Nullable(DateTime) COMMENT '接单时间', `seller_memo` Nullable(String) COMMENT '卖家备注', `buyer_momo` Nullable(String) COMMENT '买家备注', `confirm_time` Nullable(DateTime) COMMENT '确认收货时间', `shipping_type` Int8 COMMENT '配送方式1快递2同城配送3自提', `order_commit_id` String COMMENT '订单提交ID，用于拆分订单展示', `team_id` Nullable(Int64) COMMENT '拼团团队id', `pick_template_id` Nullable(Int32) COMMENT '自提id', `is_delete` Nullable(Int8) COMMENT '删除标记', `update_time` Nullable(DateTime) COMMENT '更新时间', `create_time` Nullable(DateTime) COMMENT '创建时间', `project_code` Nullable(String) COMMENT '项目编码', `cancel_reason` Nullable(Int32) COMMENT '订单取消原因(1、手动取消 2、超时自动取消 3、拒绝接单 4、超时未接单 5、)', `join_from` Nullable(String) COMMENT '加购来源', `is_settlement` Nullable(Int8) COMMENT '是否结算', `is_system` Nullable(Int8) COMMENT '是否系统生成 0否1是', `outer_order_no` Nullable(String) COMMENT '外部订单号，用于第三方', `_sign` Int8 DEFAULT 1, `_version` UInt64 DEFAULT 1) ENGINE = ReplacingMergeTree(_version) PARTITION BY intDiv(id, 4294967) ORDER BY tuple(id) SETTINGS index_granularity = 8192
;

```



```sql
CREATE TABLE ck_actrade_online.trade_spm
(

    `id` Int64(20),
    `user_id` Int64(20) COMMENT '用户id  未登录为0',
    `visitor_id` Int64(20) COMMENT '用户id  未登录为0',
    `from_type` String COMMENT '来源:ios,android,applet',
    `client_id` String COMMENT '客户端ID',
    `spm_platfrom` String COMMENT '访问平台固定；10=ios，11=小程序，12=H5 ,
13=android',
    `spm_page` String COMMENT '页面',
    `spm_model` String COMMENT '模块',
    `spm_position` String COMMENT '位置',
    `param_content` Nullable(String) COMMENT '内容(商品ID或专题模板ID或链接)',
    `ip` String COMMENT 'IP',
    `ua` String COMMENT 'User-Agent',
    `create_time` Nullable(DateTime) COMMENT '创建时间',
    `update_time` Nullable(DateTime) COMMENT '修改时间',
    `project_code` String COMMENT '项目编码',
    `_sign` Int8 DEFAULT 1,
    `_version` UInt64 DEFAULT 1
)
ENGINE = ReplacingMergeTree(_version)
PARTITION BY intDiv(id,18446744073709551)
ORDER BY tuple(id)
SETTINGS index_granularity = 8192


```

参考文档

```
https://blog.csdn.net/douglas8287/article/details/84705750
https://blog.csdn.net/xhaimail/article/details/122084999
https://www.jianshu.com/p/953ba54d434c
https://blog.csdn.net/fx9590/article/details/105163804
```



### 创建表结构

```sql
-- 本地创建spm表
CREATE TABLE default.trade_spm
(
    `id` Int64,
    `user_id` Int64 COMMENT '用户id  未登录为0',
    `from_type` String COMMENT '来源:ios,
\r\nandroid,
\r\napplet',
    `client_id` String COMMENT '客户端ID',
    `spm_platfrom` String COMMENT '访问平台固定；10=ios，11=小程序，12=H5 ,
\r\n13=android',
    `spm_page` String COMMENT '页面',
    `spm_model` String COMMENT '模块',
    `spm_position` String COMMENT '位置',
    `param_content` Nullable(String) COMMENT '内容(商品ID或专题模板ID或链接)',
    `ip` String COMMENT 'IP',
    `ua` String COMMENT 'User-Agent',
    `create_time` DateTime DEFAULT toDateTime(now(), 'Asia/Shanghai') COMMENT '行为发生时间',
    `update_time` DateTime DEFAULT toDateTime(now(), 'Asia/Shanghai') COMMENT '修改时间',
    `project_code` String COMMENT '项目编码',
    `_sign` Int8 DEFAULT 1,
    `_version` UInt64 DEFAULT 1
)
ENGINE = ReplacingMergeTree(_version)
PARTITION BY intDiv(id,
 18446744073709551)
ORDER BY tuple(id)
SETTINGS index_granularity = 8192

```

### 工程配置

环境dubbo+spring boot +nacos+swagger ui；使用nacos作为服务注册中心和配置中心

bootstrap.yml配置文件,配置nacos配置中心,使用远程配置，配置测试环境mall-log测试环境配置文件

profiles: active为 test

```yml
# nacos配置
server:
  port: 8090

spring:
  application:
    name: mall-log
  profiles:
    active: test
  cloud:
    config:
      override-none: true
      allow-override: true
      override-system-properties: false
    nacos:
      discovery:
        server-addr: 127.0.0.1:8848 #localhost:8848 #Nacos服务注册中心地址
      config:
        server-addr: 127.0.0.1:8848 #Nacos作为配置中心地址
        file-extension: yml #指定yaml格式的配置
        group: DEFAULT_GROUP
        namespace: 803931a7-6d1b-44be-a8ee-8732822722bf   #指定配置中心命名空间
```

![image-20220517112405528](文档图片/image-20220517112405528.png)

登录 127.0.0.1:8848/nacos

nacos 点击**命名空间**：看到之前以及创建了一个locolhost本地测试的命名空间，id和bootstrap.yml的 namespace配置一致：

![image-20220517113133710](文档图片/image-20220517113133710.png)

nacos点击配置列表，选择localhost命名空间，导入配置，或者克隆配置，文件名称和bootstrap.yml和application:name: mall-log 加上profiles:active: test一致，profiles:active区分是生产还是测试环境配置

![image-20220517113539318](文档图片/image-20220517113539318.png)

编辑配置如下，文件类型选择yaml

```yml
dubbo:
  application:
    name: mall-log
  protocol:
    name: dubbo
    port: 20881
  registry:
    address: nacos://127.0.0.1:8848   #使用本地nacos作为服务注册中心
    check: false
    timeout: 5000
  scan:
    base-packages: com.anchu.log.web.service
  config-center:
    check:
  consumer:
    check: false
    timeout: 5000
server:
  port: 8090 
spring:
  cloud:
    config:
      override-none: true
  datasource:
    driver-class-name: com.clickhouse.jdbc.ClickHouseDriver
    url: jdbc:clickhouse://192.168.120.110:8123/default
    userName: default
    password: clickhouse
    druid:
      # 按照自己连接的 clickhouse 数据库来
      filters: none  #clickhouse不支持wall及监控
      #配置初始化大小/最小/最大
      initial-size: 5
      min-idle: 5
      max-active: 20
      #获取连接等待超时时间
      max-wait: 60000
      #间隔多久进行一次检测，检测需要关闭的空闲连接
      time-between-eviction-runs-millis: 60000
      #一个连接在池中最小生存的时间
      min-evictable-idle-time-millis: 30000
      validation-query: SELECT 1
#mybatis
mybatis-plus:
  mapper-locations: classpath:mapper/*.xml
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
  global-config:
    db-config:
      logic-delete-field: flag  # 全局逻辑删除的实体字段名(since 3.3.0,配置后可以忽略不配置步骤2)
      logic-delete-value: 1 # 逻辑已删除值(默认为 1)
      logic-not-delete-value: 0 # 逻辑未删除值(默认为 0)

logging:
  config: classpath:log4j2.xml
```

### 代码编写（主要逻辑部分）

启动类，@EnableDiscoveryClient注解，服务发现

```java
/**
 * @author hh
 * @date 2022/4/6 16:26
 */
@SpringBootApplication(scanBasePackages = {"com.anchu.log"})
@MapperScan(basePackages = {"com.anchu.log.web.dao"})
@EnableConfigurationProperties
@EnableDiscoveryClient
@EnableAsync
public class WsnbLogApplication {

    public static void main(String[] args) {
        SpringApplication.run(WsnbLogApplication.class, args);
    }

}
```

control

```java
package com.anchu.log.web.controller;




/**
 * <p>
 * SPM 前端控制器
 * </p>
 *
 * @author autogenerator
 * @since 2021-07-27
 */
@RestController
@RequestMapping("/consumer/spm")
@Api(tags = "用户端SPM埋点")
public class TradeSpmAppController {

    @Reference
    private JwtService jwtService;

    @Autowired
    private ITradeSpmService iTradeSpmService;

    @ApiOperation(value = "增加埋点点击事件", httpMethod = "POST")
    @PostMapping(ADD)
    public ResultEntity add(HttpServletRequest request, @RequestBody TradeSpmDto dto){

        if(Objects.isNull(dto)){
            throw new CustomException(ResultEnum.PARAMS_IS_EMPTY);
        }
        String token = request.getHeader(ShiroConstants.AUTHORIZATION);

        String userAgent = request.getHeader("User-Agent");
        dto.setUserId(0L);
//        if(!Objects.isNull(token) && !("".equals(token))){
//            TradeUserDto userDto =jwtService.parseToken(token);
//            dto.setUserId(userDto.getUserId());
//        }
        dto.setUserId(1L);
        dto.setIp(IPUtil.getIp(request));
        dto.setUa(Objects.isNull(userAgent) ? "unknow" : userAgent);

        iTradeSpmService.add(dto);
        return ResultTemplate.success();
    }
}



```

swagger ui测试：

http://127.0.0.1:8090/doc.html

![image-20220517114734376](文档图片/image-20220517114734376.png)

```json
//请求体
{
	"clientId": "1",
	"fromType": "1",
	"id": 0,
	"ip": "127.0.0.1",
	"paramContent": "{\"goodId\":1}",
	"spmModel": "10",
	"spmPage": "11",
	"spmPlatfrom": "11",
	"spmPosition": "111",
	"ua": "microsoft edge",
	"userId": 1
}
```

### 问题

（1）主键不支持自增，可以业务代码自己生成，比如雪花算法id

（2）时区问题

https://blog.csdn.net/tomMMMMMMMMMMM/article/details/111636686

```shell
# 确保机器时间正确 时区确保正确，PDT是太平洋夏季时间。
[root@localhost anchu]#  date -s 2022-05-18
Wed May 18 00:00:00 PDT 2022
[root@localhost anchu]#  date -s 11:14:20
Wed May 18 11:14:20 PDT 2022
[root@localhost anchu]# hwclock --systohc
[root@localhost anchu]# date
Wed May 18 11:14:48 PDT 2022
[root@localhost anchu]# 

#修改时区
[root@localhost anchu]# ll /etc/localtime 
lrwxrwxrwx. 1 root root 41 Apr 22 12:36 /etc/localtime -> ../usr/share/zoneinfo/America/Los_Angeles
[root@localhost anchu]# ll /etc/localtime 
lrwxrwxrwx. 1 root root 41 Apr 22 12:36 /etc/localtime -> ../usr/share/zoneinfo/America/Los_Angeles
[root@localhost anchu]# ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
[root@localhost anchu]# ll /etc/localtime 
lrwxrwxrwx. 1 root root 33 May 19 03:39 /etc/localtime -> /usr/share/zoneinfo/Asia/Shanghai
[root@localhost anchu]# date
Thu May 19 03:39:22 CST 2022
[root@localhost anchu]# date -s 2022-05-18
Wed May 18 00:00:00 CST 2022
[root@localhost anchu]# date -s 12:48:30
Wed May 18 12:48:30 CST 2022

#修改clickhouse配置文件，并重启
[root@localhost anchu]# vi /etc/clickhouse-server/config.xml
<timezone>Asia/Shanghai</timezone>
[root@localhost anchu]# clickhouse restart

#查看clickhouse时区配置

localhost :) show SETTINGS like '%time_zone%';

SHOW SETTINGS LIKE '%time_zone%'

Query id: a31192e8-b011-4117-91ce-2abc86bbbeef

┌─name─────────────────┬─type─┬─value─┐
│ use_client_time_zone │ Bool │ 0     │
└──────────────────────┴──────┴───────┘
localhost :) show SETTINGS like '%time_zone%';

SET use_client_time_zone = 1;

localhost :) select toTimeZone(toDateTime(now()), 'Asia/Shanghai');

┌─toTimeZone(toDateTime(now()), 'Asia/Shanghai')─┐
│                            2022-05-18 12:50:06 │
└────────────────────────────────────────────────┘



```

（3）性能问题

由于clickhouse对高并发支持不高，其次类似标题5.1说明，**避免逐行insert或小批量的insert，update，delete操作，尽量做1000条以上批量的写入，我们可以优化代码，先将spm数据队列缓存起来，后面多并发批处理。**

队列及处理相关参考文档：

https:*//blog.csdn.net/qq_34561243/article/details/98955452*

（4）代码异常

Cannot parse string '2022-05-23 09:39:11.71' as DateTime: syntax error at position 19

```java
; bad SQL grammar []; nested exception is java.sql.SQLException: Code: 6. DB::Exception: Cannot parse string '2022-05-23 09:39:11.71' as DateTime: syntax error at position 19 (parsed just '2022-05-23 09:39:11'): while executing 'FUNCTION if(isNull(_dummy_0) : 3, defaultValueOfTypeName('DateTime') :: 2, _CAST(_dummy_0, 'DateTime') :: 4) -> if(isNull(_dummy_0), defaultValueOfTypeName('DateTime'), _CAST(_dummy_0, 'DateTime')) DateTime : 1': While executing ValuesBlockInputFormat. (CANNOT_PARSE_TEXT) (version 22.4.5.9 (official build))
, server ClickHouseNode(addr=http:192.168.120.110:8123, db=default)@387050144
```

修改如下

```
        //date 日期不支持毫秒
        String dateTime = DateUtil.formatDateTime(new Date());
        Date date = DateUtil.parse(dateTime, "yyyy-MM-dd hh:mm:ss");
        tradeSpmLogDto.setCreateTime(date);
        tradeSpmLogDto.setUpdateTime(date);
```

参考文档：

```
https://www.csdn.net/tags/OtTacgwsNDcwMy1ibG9n.html
https://blog.csdn.net/weixin_43975771/article/details/121563167
```

